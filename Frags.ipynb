{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Module C:\\Users\\evanmuis.stu\\Miniconda3\\envs\\frag\\lib\\site-packages\\pylandstats\\landscape.py has not been compiled for Transonic-Numba\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pylandstats as pls\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import fiona\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "\n",
    "wd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "propVars = [\"HMM\", \"disturbance\", \"fragstats\", \"nightlights\"]\n",
    "\n",
    "propVars = tuple([s + \".tif\" for s in propVars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 'outputs'\n",
    "parkFolders = [os.path.join(wd, d, o) for o in os.listdir(d) \n",
    "                    if os.path.isdir(os.path.join(d,o))]\n",
    "parkFolders = parkFolders[0:1]\n",
    "hmmDfs = []\n",
    "files = []\n",
    "\n",
    "for park in parkFolders:\n",
    "    parkName = park.rsplit(\"\\\\\", 1)[-1]\n",
    "    #print(parkName)\n",
    "    subzone = os.path.join(park, parkName + \"_PACE_Subzones.shp\")\n",
    "    ppa_gpe = os.path.join(park, parkName + \"_PACE.shp\")\n",
    "    #print(subzone)\n",
    "    rasterLoc = os.path.join(park, \"rasters\")\n",
    "    for file in os.listdir(rasterLoc):\n",
    "        if file.endswith(propVars):\n",
    "            files.append(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evanmuis.stu\\Sync\\Masters\\Data\\outputs\\AdamsLakeMarineParkPoplarPointSite\\rasters\\AdamsLakeMarineParkPoplarPointSite_PACE-1985-disturbance.tif \n",
      " C:\\Users\\evanmuis.stu\\Sync\\Masters\\Data\\outputs\\AdamsLakeMarineParkPoplarPointSite\\rasters\\AdamsLakeMarineParkPoplarPointSite_PACE-1986-disturbance.tif \n",
      " C:\\Users\\evanmuis.stu\\Sync\\Masters\\Data\\outputs\\AdamsLakeMarineParkPoplarPointSite\\rasters\\AdamsLakeMarineParkPoplarPointSite_PACE-1987-disturbance.tif\n"
     ]
    }
   ],
   "source": [
    "dist = os.path.join(rasterLoc, files[0])\n",
    "frag = os.path.join(rasterLoc, files[1])\n",
    "hmm = os.path.join(rasterLoc, files[2])\n",
    "print(dist, \"\\n\", frag, \"\\n\", hmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function for working with VLCE and disturbance data to get proportions of total area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propGen(fName, zones):\n",
    "\n",
    "    za = pls.ZonalAnalysis(fName, masks = zones, masks_index_col = 'ppa_gpe')\n",
    "    class_metrics_df = za.compute_class_metrics_df(metrics = ['proportion_of_landscape', 'total_area'], fillna = False)\n",
    "    class_metrics_df[\"park\"] = parkName\n",
    "    class_metrics_df[\"var\"] = var\n",
    "    class_metrics_df[\"year\"] = year\n",
    "    return class_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dissolve_ppa_gpe(shapefile):\n",
    "    read_shape = gpd.read_file(shapefile)\n",
    "    shape_dissolved = read_shape.dissolve(by = \"ppa_gpe\")\n",
    "    shape_dissolved.reset_index(level = 0, inplace = True)\n",
    "    save_name = shapefile[:-4] + \"_dissolved\" + shapefile[-4:]\n",
    "    shape_dissolved.to_file(save_name)\n",
    "    return(save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function for working with reclassified VLCE data to get fragstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fragGen(fName, zones):\n",
    "\n",
    "    \n",
    "    #create df with subzone information\n",
    "    df = gpd.read_file(zones)\n",
    "    newDf = df[[\"myFID\", \"ppa_gpe\", \"ZONE\", \"SUBZONE\", \"VARIANT\", \"PHASE\", \"NATURAL_DI\"]]\n",
    "\n",
    "    #run pylandstats, adding park, variable, year, and subzone information\n",
    "    za = pls.ZonalAnalysis(fName, masks = zones, masks_index_col = 'myFID')\n",
    "    class_metrics_df = za.compute_class_metrics_df(metrics = ['proportion_of_landscape', \"total_area\", \"number_of_patches\", \"area_mn\"], fillna = False)\n",
    "    class_metrics_df[\"park\"] = parkName\n",
    "    class_metrics_df[\"var\"] = var\n",
    "    class_metrics_df[\"year\"] = year\n",
    "    class_metrics_df = class_metrics_df.reset_index()\n",
    "    class_metrics_df = pd.merge(class_metrics_df, newDf)\n",
    "    return class_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_done = 0\n",
    "hmmDfs = []\n",
    "distDfs = []\n",
    "fragDfs = []\n",
    "fragSubzoneDfs = []\n",
    "distDfSubzones = []\n",
    "nightDfs = []\n",
    "broken_hmm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_done += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "979 / 979 folders 37 / 37 files: ZumtelaBayConservancy_PACE-2018-disturbance.tif\n",
      "C:\\Users\\evanmuis.stu\\Sync\\Masters\\Data\\outputs\\ZumtelaBayConservancy\\rasters\\ZumtelaBayConservancy_PACE-2018-disturbance.tif\n",
      "C:\\Users\\evanmuis.stu\\Sync\\Masters\\Data\\outputs\\ZumtelaBayConservancy\\ZumtelaBayConservancy_PACE_dissolved.shp\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "d = 'outputs'\n",
    "parkFolders = [os.path.join(wd, d, o) for o in os.listdir(d) \n",
    "                    if os.path.isdir(os.path.join(d,o))]\n",
    "#parkFolders = parkFolders\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for park in parkFolders[num_done:]:\n",
    "    j = 1\n",
    "    rasterLoc = os.path.join(park, \"rasters\")\n",
    "    if os.path.isdir(rasterLoc):\n",
    "        parkName = park.rsplit(\"\\\\\", 1)[-1]\n",
    "        #print(parkName)\n",
    "        subzone = os.path.join(park, parkName + \"_PACE_Subzones.shp\")\n",
    "        ppa_gpe = os.path.join(park, parkName + \"_PACE.shp\")\n",
    "        ppa_gpe = dissolve_ppa_gpe(ppa_gpe)\n",
    "        #print(subzone)\n",
    "    \n",
    "        tifs = []\n",
    "        for file in os.listdir(rasterLoc):\n",
    "            if file.endswith(propVars):\n",
    "                tifs.append(file)\n",
    "        #print(tifs)\n",
    "        for file in tifs:\n",
    "            clear_output(wait = True)\n",
    "            print(str(num_done + 1), \"/\", len(parkFolders), \"folders\", str(j), \"/\", len(tifs), \"files:\", file)\n",
    "\n",
    "            fileLoc = os.path.join(rasterLoc, file)\n",
    "            print(fileLoc)\n",
    "            print(ppa_gpe)\n",
    "            if file.endswith(propVars[0]): #vlce data\n",
    "                try:\n",
    "                    hmmDf = propGen(fileLoc, ppa_gpe)\n",
    "                    hmmDfs.append(hmmDf)\n",
    "                except:\n",
    "                    broken_hmm.append(fileLoc)\n",
    "                    pass\n",
    "            if file.endswith(propVars[1]): #disturbance data\n",
    "                \n",
    "                distDf = propGen(fileLoc, ppa_gpe)\n",
    "                distDfs.append(distDf)\n",
    "\n",
    "                distDfSubzone = fragGen(fileLoc, subzone)\n",
    "                distDfSubzones.append(distDfSubzone)\n",
    "\n",
    "            if file.endswith(propVars[2]): #fragstats\n",
    "                fragDf = propGen(fileLoc, ppa_gpe)\n",
    "                fragDfs.append(fragDf)\n",
    "                fragSubzoneDf = fragGen(fileLoc, subzone)\n",
    "                fragSubzoneDfs.append(fragSubzoneDf)\n",
    "\n",
    "            if file.endswith(propVars[3]): #nightlights\n",
    "                nightDf = propGen(fileLoc, ppa_gpe)\n",
    "                nightDfs.append(nightDf)\n",
    "            j += 1\n",
    "\n",
    "    num_done += 1    \n",
    "\n",
    "pd.concat(hmmDfs).fillna(0).to_csv(\"outputCsvs/vlce.csv\")\n",
    "pd.concat(distDfs).fillna(0).to_csv(\"outputCsvs/disturbance.csv\")\n",
    "pd.concat(distDfSubzones).fillna(0).to_csv(\"outputCsvs/disturbance_subzones.csv\")\n",
    "pd.concat(fragSubzoneDfs).fillna(0).to_csv(\"outputCsvs/fragSubzones.csv\")\n",
    "pd.concat(nightDfs).fillna(0).to_csv(\"outputCsvs/nightlights.csv\")\n",
    "pd.concat(fragDfs).fillna(0).to_csv(\"outputCsvs/fragPpaGpe.csv\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# broke\n",
    "elephanthill - marti fixing\n",
    "RM - size issues\n",
    "Spats - size issues\n",
    "tweeds - size issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subzone_split(pace_subzone):\n",
    "\n",
    "    subzone_shp = gpd.read_file(pace_subzone)\n",
    "\n",
    "    keep_columns = subzone_shp.columns[[0, 1, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 26, 32, 33]]\n",
    "    #print(keep_columns)\n",
    "\n",
    "    ppa_subzones_filename = \"scratch/ppa_subzones.shp\"\n",
    "    ppa_subzones = subzone_shp[subzone_shp.ppa_gpe == \"PPA\"]\n",
    "    ppa_subzones = ppa_subzones[ppa_subzones.columns.intersection(keep_columns)]\n",
    "    ppa_subzones.to_file(ppa_subzones_filename)\n",
    "\n",
    "    gpe_subzones_filename = \"scratch/gpe_subzones.shp\"\n",
    "    gpe_subzones = subzone_shp[subzone_shp.ppa_gpe == \"GPE\"]\n",
    "    gpe_subzones = gpe_subzones[gpe_subzones.columns.intersection(keep_columns)]\n",
    "    gpe_subzones.to_file(gpe_subzones_filename)\n",
    "\n",
    "    return ppa_subzones_filename, gpe_subzones_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_subzones(shapefile_path, raster_path):\n",
    "\n",
    "    with fiona.open(shapefile_path) as shapefile:\n",
    "        shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "        out_meta = src.meta\n",
    "\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                     \"height\": out_image.shape[1],\n",
    "                     \"width\": out_image.shape[2],\n",
    "                     \"transform\": out_transform})\n",
    "    \n",
    "    if \"ppa\" in shapefile_path:\n",
    "        save_location = \"scratch/ppa_raster.tif\"\n",
    "    if \"gpe\" in shapefile_path:\n",
    "        save_location = \"scratch/gpe_raster.tif\"\n",
    "        \n",
    "    with rasterio.open(save_location, \"w\", **out_meta) as dest:\n",
    "        dest.write(out_image)\n",
    "        \n",
    "    return save_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_parks = [\"RM\", \"Spats\", \"Tweeds\"]\n",
    "park_paths = [os.path.join(\"outputs\", park) for park in broken_parks]\n",
    "raster_paths = [os.path.join(park, \"rasters\") for park in park_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_hmmDfs = []\n",
    "large_distDfs = []\n",
    "large_distDfsSubzone = []\n",
    "large_fragDfs = []\n",
    "large_fragDfsSubzone = []\n",
    "large_nightDfs = []\n",
    "\n",
    "num_done = 0\n",
    "j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 / 3 folders 37 / 37 files: outputs\\Tweeds\\rasters\\Tweeds_PACE-2018-disturbance.tif\n",
      "Tweeds 2018 disturbance\n",
      "outputs\\Tweeds\\Tweeds_PACE_dissolved.shp\n",
      "outputs\\Tweeds\\Tweeds_PACE_Subzones.shp\n",
      "outputs\\Tweeds\\rasters\\Tweeds_PACE-2018-disturbance.tif\n",
      "done disturbance all\n"
     ]
    }
   ],
   "source": [
    "for parkName in broken_parks[num_done:]:\n",
    "    \n",
    "    #parkName = \"Spats\"\n",
    "    park_path = os.path.join(\"outputs\", parkName)\n",
    "    raster_location = os.path.join(park_path, \"rasters\")\n",
    "\n",
    "    ppa_gpe = os.path.join(park_path, parkName + \"_PACE.shp\")\n",
    "    subzone = os.path.join(park_path, parkName + \"_PACE_Subzones.shp\")\n",
    "    ppa_gpe = dissolve_ppa_gpe(ppa_gpe)\n",
    "\n",
    "    #split_names = subzone_split(subzone)\n",
    "    #ppa_subzones = split_names[0]\n",
    "    #gpe_subzones = split_names[1]\n",
    "\n",
    "    tifs = []\n",
    "    for file in os.listdir(raster_location):\n",
    "        if file.endswith(propVars):\n",
    "            tifs.append(os.path.join(raster_location, file))\n",
    "\n",
    "    for file in tifs[j:]:\n",
    "        \n",
    "        year = file.split(\"\\\\\")[-1].split(\".\")[0].split(\"-\")[1]\n",
    "        var = file.split(\"\\\\\")[-1].split(\".\")[0].split(\"-\")[-1]\n",
    "        \n",
    "        clear_output(wait = True)\n",
    "        print(str(num_done + 1), \"/\", len(broken_parks), \"folders\", str(j + 1), \"/\", len(tifs), \"files:\", file)\n",
    "        print(parkName, year, var)\n",
    "        print(ppa_gpe)\n",
    "        print(subzone)\n",
    "        print(file)\n",
    "        \n",
    "        \n",
    "        if file.endswith(propVars[0]): #vlce\n",
    "            hmmDf = propGen(file, ppa_gpe)\n",
    "            large_hmmDfs.append(hmmDf)\n",
    "\n",
    "        if file.endswith(propVars[1]): #disturbance\n",
    "            distDf = propGen(file, ppa_gpe)\n",
    "            large_distDfs.append(distDf)\n",
    "            print(\"done disturbance all\")\n",
    "            \n",
    "            \n",
    "            #ppa_raster = clip_subzones(ppa_subzones, file)\n",
    "\n",
    "            #print(\"working on subzone ppa\")\n",
    "            #distDfSubzone = fragGen(ppa_raster, ppa_subzones)\n",
    "            #large_distDfsSubzone.append(distDfSubzone)\n",
    "            #print(\"done disturbance ppa\")\n",
    "\n",
    "            #gpe_raster = clip_subzones(gpe_subzones, file)\n",
    "            \n",
    "            #print(\"working on subzone gpe\")\n",
    "            #distDfSubzone = fragGen(gpe_raster, gpe_subzones)\n",
    "            #large_distDfsSubzone.append(distDfSubzone)\n",
    "            #print(\"done disturbance gpe\")\n",
    "\n",
    "        if file.endswith(propVars[2]): #fragstats\n",
    "            fragDf = propGen(file, ppa_gpe)\n",
    "            large_fragDfs.append(fragDf)\n",
    "            print(\"done frags all\")\n",
    "\n",
    "            #ppa_raster = clip_subzones(ppa_subzones, file)\n",
    "            #print(\"working on subzone ppa\")\n",
    "            #fragDfSubzone = fragGen(ppa_raster, ppa_subzones)\n",
    "            #large_fragDfsSubzone.append(distDfSubzone)\n",
    "            #print(\"done frags ppa gpe\")\n",
    "\n",
    "            #gpe_raster = clip_subzones(gpe_subzones, file)\n",
    "            #print(\"working on subzone\")\n",
    "            #fragDfSubzone = fragGen(gpe_raster, gpe_subzones)\n",
    "            #large_fragDfsSubzone.append(distDfSubzone)\n",
    "            #print(\"done frags gpe\")\n",
    "\n",
    "        if file.endswith(propVars[3]): #nightlights\n",
    "            nightDf = propGen(file, ppa_gpe)\n",
    "            large_nightDfs.append(nightDf)\n",
    "        j += 1\n",
    "    num_done += 1\n",
    "    j = 0\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(large_hmmDfs).fillna(0).to_csv(\"outputCsvs/large_vlce.csv\")\n",
    "pd.concat(large_distDfs).fillna(0).to_csv(\"outputCsvs/large_disturbance.csv\")\n",
    "#pd.concat(large_distDfsSubzone).fillna(0).to_csv(\"outputCsvs/large_disturbance_subzones.csv\")\n",
    "#pd.concat(large_fragDfsSubzone).fillna(0).to_csv(\"outputCsvs/large_fragSubzones.csv\")\n",
    "pd.concat(large_nightDfs).fillna(0).to_csv(\"outputCsvs/large_nightlights.csv\")\n",
    "pd.concat(large_fragDfs).fillna(0).to_csv(\"outputCsvs/large_fragPpaGpe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
